{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FaceRecognization_usingCNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1g30XK9IkYK_MMB9X2XaCjbpFirM0OEBS",
      "authorship_tag": "ABX9TyNh5mi226RNf5E/SEEYV2y0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AkshaySingh-Github/Deep-Learning-CNN-model-to-recognize-face/blob/main/FaceRecognization_usingCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzcYiOPwMq1I"
      },
      "source": [
        "# Deep Learning CNN model to recognize face"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miiIu8f__SlZ",
        "outputId": "ec2d9a1c-5b37-4141-8072-b119b1da8037"
      },
      "source": [
        "\n",
        "#IMAGE PRE-PROCESSING for TRAINING and TESTING data\n",
        " \n",
        "# Specifying the folder where images are present\n",
        "TrainingImagePath='/content/drive/MyDrive/Data/Face Images/Final Training Images'\n",
        " \n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        " \n",
        "# Defining pre-processing transformations on raw images of training data\n",
        "# These hyper parameters helps to generate slightly twisted versions\n",
        "train_datagen = ImageDataGenerator(rescale=1./255\n",
        "        shear_range=0.1,\n",
        "        zoom_range=0.1,\n",
        "        horizontal_flip=True)\n",
        " \n",
        "# Defining pre-processing transformations on raw images of testing data\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        " \n",
        "# Generating the Training Data\n",
        "training_set = train_datagen.flow_from_directory(TrainingImagePath, target_size=(64, 64),batch_size=32,class_mode='categorical')\n",
        " \n",
        " \n",
        "# Generating the Testing Data\n",
        "test_set = test_datagen.flow_from_directory(TrainingImagePath,target_size=(64, 64), batch_size=32,class_mode='categorical')\n",
        " \n",
        "# Printing class labels for each face\n",
        "test_set.class_indices"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 244 images belonging to 16 classes.\n",
            "Found 244 images belonging to 16 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'face1': 0,\n",
              " 'face10': 1,\n",
              " 'face11': 2,\n",
              " 'face12': 3,\n",
              " 'face13': 4,\n",
              " 'face14': 5,\n",
              " 'face15': 6,\n",
              " 'face16': 7,\n",
              " 'face2': 8,\n",
              " 'face3': 9,\n",
              " 'face4': 10,\n",
              " 'face5': 11,\n",
              " 'face6': 12,\n",
              " 'face7': 13,\n",
              " 'face8': 14,\n",
              " 'face9': 15}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtNtCZz_HC-d"
      },
      "source": [
        "# Creating a mapping for index and face names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osgFGHfoHD9B",
        "outputId": "bc67f12d-3abe-4d42-f60d-217a631be0a7"
      },
      "source": [
        "#Creating lookup table for all faces\n",
        "# class_indices have the numeric tag for each face\n",
        "\n",
        "TrainClasses=training_set.class_indices\n",
        " \n",
        "# Storing the face and the numeric tag for future reference\n",
        "ResultMap={}\n",
        "for faceValue,faceName in zip(TrainClasses.values(),TrainClasses.keys()):\n",
        "    ResultMap[faceValue]= faceName\n",
        " \n",
        "# Saving the face map for future reference\n",
        "import pickle\n",
        "with open(\"FaceResultsMap.pkl\", 'wb') as fileWriteStream:\n",
        "    pickle.dump(ResultMap, fileWriteStream)\n",
        " \n",
        "# The model will give answer as a numeric tag\n",
        "# This mapping will help to get the corresponding face name for it\n",
        "print(\"Mapping of Face and its ID\",ResultMap)\n",
        " \n",
        "# The number of neurons for the output layer is equal to the number of faces\n",
        "OutputNeurons=len(ResultMap)\n",
        "print('\\n The Number of output neurons: ', OutputNeurons)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mapping of Face and its ID {0: 'face1', 1: 'face10', 2: 'face11', 3: 'face12', 4: 'face13', 5: 'face14', 6: 'face15', 7: 'face16', 8: 'face2', 9: 'face3', 10: 'face4', 11: 'face5', 12: 'face6', 13: 'face7', 14: 'face8', 15: 'face9'}\n",
            "\n",
            " The Number of output neurons:  16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0DhfFeLHXBS"
      },
      "source": [
        "#Creating the CNN face recognition model\n",
        "\n",
        "### In the below code snippet, I have created a CNN model with\n",
        "\n",
        "2 hidden layers of convolution\n",
        "\n",
        "2 hidden layers of max pooling\n",
        "\n",
        "1 layer of flattening\n",
        "\n",
        "1 Hidden ANN layer\n",
        "\n",
        "1 output layer with 16-neurons (one for each face)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3SXIsxcHT4G"
      },
      "source": [
        "# Create CNN deep learning model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPool2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        " \n",
        "#Initializing the Convolutional Neural Network\n",
        "classifier= Sequential()\n",
        " \n",
        "#STEP--1 Convolution\n",
        "# Adding the first layer of CNN\n",
        "classifier.add(Convolution2D(32, kernel_size=(5, 5), strides=(1, 1), input_shape=(64,64,3), activation='relu'))\n",
        " \n",
        "# STEP--2 MAX Pooling\n",
        "classifier.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "# ADDITIONAL LAYER of CONVOLUTION for better accuracy \n",
        "classifier.add(Convolution2D(64, kernel_size=(5, 5), strides=(1, 1), activation='relu'))\n",
        " \n",
        "classifier.add(MaxPool2D(pool_size=(2,2)))\n",
        " \n",
        "# STEP--3 FLattening\n",
        "classifier.add(Flatten())\n",
        " \n",
        "# STEP--4 Fully Connected Neural Network\n",
        "classifier.add(Dense(64, activation='relu'))\n",
        " \n",
        "classifier.add(Dense(OutputNeurons, activation='softmax'))\n",
        " \n",
        "# Compiling the CNN\n",
        "#classifier.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "classifier.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics=[\"accuracy\"])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkwlhVDQH9I7",
        "outputId": "c2f8339b-2a6e-4f94-cd1f-7f2be730400f"
      },
      "source": [
        "import time\n",
        "# Measuring the time taken by the model to train\n",
        "StartTime=time.time()\n",
        " \n",
        "# Starting the model training\n",
        "classifier.fit_generator(\n",
        "                    training_set,\n",
        "                    steps_per_epoch=30,\n",
        "                    epochs=10,\n",
        "                    validation_data=test_set,\n",
        "                    validation_steps=10)\n",
        " \n",
        "EndTime=time.time()\n",
        "print(\"###### Total Time Taken: \", round((EndTime-StartTime)/60), 'Minutes ######')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1915: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            " 8/30 [=======>......................] - ETA: 2:51 - loss: 95.5128 - accuracy: 0.0704 WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 300 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10 batches). You may need to use the repeat() function when building your dataset.\n",
            "30/30 [==============================] - 82s 2s/step - loss: 72.1036 - accuracy: 0.0759 - val_loss: 3.7208 - val_accuracy: 0.1025\n",
            "###### Total Time Taken:  2 Minutes ######\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewqIjD5zIGdg"
      },
      "source": [
        "# Testing the CNN classifier on unseen images(Validation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uj8aCLfpIHKz",
        "outputId": "ded4beab-a21c-46b8-b43c-5a6f7cec4c27"
      },
      "source": [
        "# Making single predictions\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        " \n",
        "ImagePath='/content/drive/MyDrive/Data/Face Images/Final Testing Images/face1/3face1.jpg'\n",
        "test_image=image.load_img(ImagePath,target_size=(64, 64))\n",
        "test_image=image.img_to_array(test_image)\n",
        " \n",
        "test_image=np.expand_dims(test_image,axis=0)\n",
        " \n",
        "result=classifier.predict(test_image,verbose=0)\n",
        "#print(training_set.class_indices)\n",
        " \n",
        "print('####'*10)\n",
        "print('Prediction is: ',ResultMap[np.argmax(result)])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "########################################\n",
            "Prediction is:  face14\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}